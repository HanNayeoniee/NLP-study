{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 02-LSTM_char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP07p8gql03TF3FDxWbitru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanNayeoniee/NLP-study/blob/main/Week%2002-LSTM_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW1Lq54Sby4S"
      },
      "source": [
        "### PyTorch LSTM 예제\r\n",
        "\r\n",
        "현재 문장을 주고 다음 문장 예측하기\r\n",
        "\r\n",
        "http://cedartrees.co.kr/index.php/2020/08/01/pytorch-lstm-example/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byjb8F90b2Ns"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8Vn4SAycDgi"
      },
      "source": [
        "# 'I'가 들어오면 'n'을, 'n'이 들어오면 공백을 예측\r\n",
        "sentence = \"In the beginning God created the heavens and the earth\"\r\n",
        "\r\n",
        "x = sentence[:-1]  # 입력 문장\r\n",
        "y = sentence[1:]  # 정답 데이터셋\r\n",
        "\r\n",
        "char_set = list(set(sentence))  # 문장 안의 모든 알파벳\r\n",
        "input_size = len(char_set)\r\n",
        "hidden_size = len(char_set)\r\n",
        "\r\n",
        "# 각각 문자를 one-hot 형태로 입력하기 위해 만든 딕셔너리\r\n",
        "index2char = {i:c for i, c in enumerate(char_set)}\r\n",
        "char2index = {c:i for i, c in enumerate(char_set)}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lAeHG8cdftl",
        "outputId": "e39f2107-4508-4574-960c-45275c2f9d68"
      },
      "source": [
        "char2index"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'G': 15,\n",
              " 'I': 13,\n",
              " 'a': 1,\n",
              " 'b': 5,\n",
              " 'c': 4,\n",
              " 'd': 7,\n",
              " 'e': 12,\n",
              " 'g': 2,\n",
              " 'h': 14,\n",
              " 'i': 10,\n",
              " 'n': 6,\n",
              " 'o': 11,\n",
              " 'r': 16,\n",
              " 's': 9,\n",
              " 't': 3,\n",
              " 'v': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TVHgNiBdi4V"
      },
      "source": [
        "one_hot = []\r\n",
        "for i, tkn in enumerate(x):\r\n",
        "    one_hot.append(np.eye(len(char_set), dtype='int')[char2index[tkn]])\r\n",
        "\r\n",
        "x_train = torch.Tensor(one_hot)\r\n",
        "x_train = x_train.view(1, len(x), -1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LcYzrw2dzjl",
        "outputId": "52fc21b3-37c1-4c78-abb0-2fbe457cc9de"
      },
      "source": [
        "# x_train은 3차원의 형태: [1, 10, 8]\r\n",
        "# 1: 문장의 개수, 10: 단어의 개수, 8: 단어의 입력 차원\r\n",
        "print(x_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWzol_skeJjP"
      },
      "source": [
        "y_data = [char2index[c] for c in y]\r\n",
        "y_data = torch.Tensor(y_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "340M4m8weTtW",
        "outputId": "e17f7af4-b1e2-481b-ad8a-d2bac06506ef"
      },
      "source": [
        "class RNN(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size):\r\n",
        "        super().__init__()\r\n",
        "        self.input_size = input_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "\r\n",
        "        self.rnn = nn.LSTM(\r\n",
        "            input_size = input_size,\r\n",
        "            hidden_size = hidden_size,\r\n",
        "            num_layers = 4,\r\n",
        "            batch_first = True,\r\n",
        "            bidirectional = True\r\n",
        "        )\r\n",
        "\r\n",
        "        self.layers = nn.Sequential(\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(input_size*2, hidden_size)\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        y, _ = self.rnn(x)\r\n",
        "        y = self.layers(y)\r\n",
        "        return y\r\n",
        "\r\n",
        "model = RNN(input_size, hidden_size)\r\n",
        "model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (rnn): LSTM(17, 17, num_layers=4, batch_first=True, bidirectional=True)\n",
              "  (layers): Sequential(\n",
              "    (0): ReLU()\n",
              "    (1): Linear(in_features=34, out_features=17, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XOmEZg-e54y",
        "outputId": "e4461208-af2d-484e-e7ec-c619880d17e8"
      },
      "source": [
        "# loss & optimizer setting\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters())\r\n",
        "# start training\r\n",
        "for i in range(5000):\r\n",
        "    model.train()\r\n",
        "    outputs = model(x_train)\r\n",
        "    loss = criterion(outputs.view(-1, input_size), y_data.view(-1).long())\r\n",
        "    \r\n",
        "    optimizer.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "    if i%500 == 0:\r\n",
        "        result = outputs.data.numpy().argmax(axis=2)\r\n",
        "        result_str = ''.join([char_set[c] for c in np.squeeze(result)])\r\n",
        "        print(i, \"loss: \", loss.item(), \"\\nprediction: \", result, \"\\ntrue Y: \", y_data, \"\\nprediction str: \", result_str,\"\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 loss:  2.8392279148101807 \n",
            "prediction:  [[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            "  7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 2]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  ddddddddddddddddddddddddddddddddddddddddddddddddddddg \n",
            "\n",
            "500 loss:  1.782058596611023 \n",
            "prediction:  [[ 6  0  3  3 12 12 12 12 10 10  6  6  6  6  6  6  0  0  0  0  0 12 12 12\n",
            "  12 12 12 12 12 12 12 12 12 12 12 12 12 12  0  0  0  0  0  0  0  0 12 12\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n tteeeeiinnnnnn     eeeeeeeeeeeeeeeee        eeearth \n",
            "\n",
            "1000 loss:  1.2649880647659302 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6  6  6  6  0 15 11  7  0  0  0 12 12\n",
            "  12 12 12 12 12 12 12 12 12 12 12  1 12  6  6  6  6  6  0  0  0  0 12 12\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginnnnn God   eeeeeeeeeeeeeaennnnn    eeearth \n",
            "\n",
            "1500 loss:  0.837412416934967 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6  6  6  2  0 15 11  7  0  4 16 12  1\n",
            "   1  3  3  3  3 14 14 14 14 12 12 12 12  6  9  6  6  6  7  0  0 14 12 12\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginnnng God creaatttthhhheeeensnnnd  heeearth \n",
            "\n",
            "2000 loss:  0.6475057601928711 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6  6  6  2  0 15 11  7  0  4 16 12  1\n",
            "   1  3  7  3  3 14 14 14 14 12  1 12 12  9  9  6  6  6  7  0  0 14 12 12\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginnnng God creaatdtthhhheaeessnnnd  heeearth \n",
            "\n",
            "2500 loss:  0.5067400932312012 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6  6  6  2  0 15 11  7  0  4 16 12  1\n",
            "   3 12  7  3  3 14 12 14 14 12  1  8 12  9  9  1  1  6  7  0  3 14 12  0\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginnnng God createdtthehheavessaand the earth \n",
            "\n",
            "3000 loss:  0.3659525215625763 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6  6  6  2  0 15 11  7  0  4 16 12  1\n",
            "   3 12  7  0  3 14 12 12 14 12  1  8 12  6  9  0  1  6  7  0  3 14 12  0\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginnnng God created theeheavens and the earth \n",
            "\n",
            "3500 loss:  0.216116800904274 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6 10  6  2  0 15 11  7  0  4 16 12  1\n",
            "   3 12  7  0  3 14 12 12 14 12  1  8 12  6  9  0  1  6  7  0  3 14 12  0\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginning God created theeheavens and the earth \n",
            "\n",
            "4000 loss:  0.10512101650238037 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6 10  6  2  0 15 11  7  0  4 16 12  1\n",
            "   3 12  7  0  3 14 12  0 14 12  1  8 12  6  9  0  1  6  7  0  3 14 12  0\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginning God created the heavens and the earth \n",
            "\n",
            "4500 loss:  0.04478028044104576 \n",
            "prediction:  [[ 6  0  3 14 12  0  5 12  2 10  6  6 10  6  2  0 15 11  7  0  4 16 12  1\n",
            "   3 12  7  0  3 14 12  0 14 12  1  8 12  6  9  0  1  6  7  0  3 14 12  0\n",
            "  12  1 16  3 14]] \n",
            "true Y:  tensor([ 6.,  0.,  3., 14., 12.,  0.,  5., 12.,  2., 10.,  6.,  6., 10.,  6.,\n",
            "         2.,  0., 15., 11.,  7.,  0.,  4., 16., 12.,  1.,  3., 12.,  7.,  0.,\n",
            "         3., 14., 12.,  0., 14., 12.,  1.,  8., 12.,  6.,  9.,  0.,  1.,  6.,\n",
            "         7.,  0.,  3., 14., 12.,  0., 12.,  1., 16.,  3., 14.]) \n",
            "prediction str:  n the beginning God created the heavens and the earth \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NGquOwJfSUA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}